{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mobile-chess",
   "metadata": {},
   "source": [
    "## **Simple neural network with Pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('../data', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "idx = 1000\n",
    "plt.imshow(train_dataset.data[idx], cmap='gray')\n",
    "plt.title(f'Class: {train_dataset.targets[idx]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, **{'batch_size': 32})\n",
    "test_loader = DataLoader(test_dataset, **{'batch_size': 32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLayerNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneLayerNN, self).__init__()\n",
    "        # define layers here\n",
    "        self.fc = nn.Linear(784, 10)  # fc => fully connected layer, 28 * 28 = 784\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(126)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # check device\n",
    "model = OneLayerNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # variant of gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "n_epochs = 1  # change here\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_data):\n",
    "    logit = model(input_data.unsqueeze(-1))\n",
    "    y_pred = F.softmax(logit, dim=1).argmax(dim=-1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(test_loader))\n",
    "idx = 3\n",
    "sample, y = data[idx], target[idx]\n",
    "plt.imshow(sample.squeeze(0), cmap='gray')\n",
    "plt.title(f'Actual class: {y}, Predicted class: {predict(sample)[0]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all\n",
    "y_true, y_pred = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        y_true.extend(target.tolist())\n",
    "        y_pred.extend(pred.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision, Recall, F1-score\", precision_recall_fscore_support(y_true, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-theater",
   "metadata": {},
   "source": [
    "## **Adding a layer to our neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleLayerNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DoubleLayerNN, self).__init__()\n",
    "        # define layers here\n",
    "        self.fc1 = nn.Linear(784, 100)  # fc => fully connected layer, 28 * 28 = 784\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        logit = F.log_softmax(x, dim=1)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DoubleLayerNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "n_epochs = 2  # change here\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all\n",
    "y_true, y_pred = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        y_true.extend(target.tolist())\n",
    "        y_pred.extend(pred.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision, Recall, F1-score\", precision_recall_fscore_support(y_true, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-disposition",
   "metadata": {},
   "source": [
    "## **Convolutional Neural Network (CCN)**\n",
    "\n",
    "Reference: https://github.com/pytorch/examples/blob/master/mnist/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = CNN().to(device)\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.train()\n",
    "n_epochs = 2  # try changing \n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model_cnn(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all\n",
    "y_true, y_pred = [], []\n",
    "model_cnn.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model_cnn(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        y_true.extend(target.tolist())\n",
    "        y_pred.extend(pred.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision, Recall, F1-score\", precision_recall_fscore_support(y_true, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-guess",
   "metadata": {},
   "source": [
    "## **Transfer learning**\n",
    "\n",
    "Reference: https://github.com/udacity/deep-learning-v2-pytorch/blob/master/transfer-learning/Transfer_Learning_Solution.ipynb\n",
    "\n",
    "Download data from [here](https://s3.amazonaws.com/video.udacity-data.com/topher/2018/September/5baa60a0_flower-photos/flower-photos.zip)\n",
    "\n",
    "``` sh\n",
    "wget https://s3.amazonaws.com/video.udacity-data.com/topher/2018/September/5baa60a0_flower-photos/flower-photos.zip\n",
    "unzip flower_photos.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../flower_photos/'\n",
    "train_dir = op.join(data_dir, 'train/')\n",
    "test_dir = op.join(data_dir, 'test/')\n",
    "\n",
    "classes = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "num_workers = 0\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-candy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg16.to(device) # print out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = vgg16.classifier[6].in_features\n",
    "vgg16.classifier[6] = nn.Linear(n_inputs, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.train()\n",
    "n_epochs = 2  # try changing \n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        output = vgg16(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all\n",
    "y_true, y_pred = [], []\n",
    "vgg16.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = vgg16(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        y_true.extend(target.tolist())\n",
    "        y_pred.extend(pred.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision, Recall, F1-score\", precision_recall_fscore_support(y_true, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-yukon",
   "metadata": {},
   "source": [
    "## **Print out example prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.to(\"cpu\")  # transfer model back to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images.numpy()\n",
    "\n",
    "output = vgg16(images)\n",
    "_, preds_tensor = torch.max(output, 1)\n",
    "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
    "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-consequence",
   "metadata": {},
   "source": [
    "## **Homework**\n",
    "\n",
    "No writing this week. Run the code and submit writing in PDF format\n",
    "- CNN: Try changing kernel size in convolutional neural network and rerun the code. Submit your code and prediction scores.\n",
    "- Transfer learning: Try replacing the model with 2 fully connected layers instead (hint: use [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) to add the layers)\n",
    "- Apply different transforms to data augementation process, put your code and explain if it improves prediction performance\n",
    "- **Extra 5 points**: Run transfer learning on dog breed classification datasets (https://www.kaggle.com/c/dog-breed-identification/overview), submit and show your results to the class next week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-governor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
