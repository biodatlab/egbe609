{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufk7HZMTr_Jv"
      },
      "source": [
        "# EGBE 606 - Lecture 1 : Introduction to Machine Learning\n",
        "Some nice header placed here : P"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFdFZ3Y-svTr"
      },
      "source": [
        "## 0 - Setup\n",
        "Please run this `code cell`  to make sure that everything is ready."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqbna6vN50Of"
      },
      "source": [
        "### Prerequisites Setup\n",
        "\n",
        "This setup is needed when the external modules is used. For example, Tensorflow, or other 3rd party modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6unfzHW52eZ"
      },
      "outputs": [],
      "source": [
        "# Prerequisites Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnySFqmT55JZ"
      },
      "source": [
        "### Import Modules, Functions and Constant\n",
        "Import modules for using on this file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85YDrmwq561Y"
      },
      "outputs": [],
      "source": [
        "# Pandas Module : For Dataframe Manager\n",
        "import pandas as pd\n",
        "\n",
        "# Numpy : Array operations.\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib : Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seaborn: statistical data visualization \n",
        "import seaborn as sns\n",
        "\n",
        "# Use `inline` mode for visualizing the figure directly on Colab.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import Test/Train dataset splitter module from scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import the model class from scikit-learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# scikit-learn.Metrics : Module for quantifying the quality of predictions\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMKEhaFQ5-99"
      },
      "source": [
        "# 1 - Linear Regesssion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYb2JspB6KwR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "TAn0yII26Mod",
        "outputId": "624c9696-2db9-4410-f42b-5e3c81a76a7d"
      },
      "outputs": [],
      "source": [
        "# Create random Number Generator Object\n",
        "rng = np.random.RandomState(1)  # Seed = 1\n",
        "\n",
        "# Generate datapoints\n",
        "X = 10 * rng.rand(5)\n",
        "Y  = 2 * X - 5 + (rng.randn(5)*2)\n",
        "\n",
        "# Plot datapoints\n",
        "plt.scatter(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaHdXzC-6MiS"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "model = LinearRegression(fit_intercept=True) # Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).\n",
        "\n",
        "\n",
        "model.fit(X[:, np.newaxis], Y)\n",
        "\n",
        "xfit = np.linspace(0, 10, 100)\n",
        "yfit = model.predict(xfit[:, np.newaxis])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gBmMoVdUFl79",
        "outputId": "f430bd4c-4635-4734-9d48-80e6e486f695"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X, Y)\n",
        "plt.plot(xfit, yfit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "APAxvMPnFeRL",
        "outputId": "00b6d721-2407-40f9-9b10-da8902a67042"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X, Y)\n",
        "plt.plot(xfit, yfit)\n",
        "\n",
        "dt = Y - model.predict(X[:, np.newaxis])\n",
        "data_line, caplines, barlinecol = plt.errorbar(X, Y, yerr=dt, fmt='.k', uplims=True)\n",
        "\n",
        "for capline in caplines:\n",
        "    capline.set_marker('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OksNnIA6PdW",
        "outputId": "291a76cb-c68f-481e-bb06-2a3b0caf8112"
      },
      "outputs": [],
      "source": [
        "print(\"Model slope:     \", model.coef_[0])\n",
        "print(\"Model coef:      \", model.coef_)\n",
        "print(\"Model intercept: \", model.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUPNfHbRJFgV",
        "outputId": "34dd82bb-e22b-4775-a2f6-c905ac4ca0d4"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# MAE - > Take Abs -> Less sensitive to Outlier\n",
        "# MSE - > Error Square -> Lot sensitive to Outlier\n",
        "# RMSE - > Add sqrt -> Norm to same domain as input\n",
        "# https://heartbeat.comet.ml/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\n",
        "\n",
        "# Cost Function - R^2, MSE, RMSE, MAE\n",
        "Y_predicted = model.predict(X[:, np.newaxis])\n",
        "\n",
        "r2_score = metrics.r2_score(Y, Y_predicted)\n",
        "mse = metrics.mean_squared_error(Y, Y_predicted, squared = True)\n",
        "rmse = metrics.mean_squared_error(Y, Y_predicted, squared = False)\n",
        "mae = metrics.mean_absolute_error(Y, Y_predicted)\n",
        "\n",
        "print(\"R^2:  \", r2_score)\n",
        "print(\"MSE:  \", mse)\n",
        "print(\"RMSE: \", rmse)\n",
        "print(\"MAE:  \", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPxqwUjnXzXd",
        "outputId": "8e2382d5-326c-4c95-fdd8-98dcff7a9264"
      },
      "outputs": [],
      "source": [
        "# DIY\n",
        "Y_actual = Y\n",
        "Y_predicted = model.predict(X[:, np.newaxis])\n",
        "\n",
        "n_point = len(Y_actual)\n",
        "error = np.array(Y_actual - Y_predicted)\n",
        "\n",
        "mae = np.mean(np.abs(error))\n",
        "mse = np.mean(error**2)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "y_mean = np.mean(Y_actual)\n",
        "ymeandiffsqre = (Y - y_mean)**2\n",
        "yhatmeandiffsqre = (Y_predicted - y_mean)**2\n",
        "r2_score = np.sum(yhatmeandiffsqre) / np.sum(ymeandiffsqre)\n",
        "\n",
        "print(\"R^2:  \", r2_score)\n",
        "print(\"MSE:  \", mse)\n",
        "print(\"RMSE: \", rmse)\n",
        "print(\"MAE:  \", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MA5tFKK6XCR"
      },
      "outputs": [],
      "source": [
        "rng = np.random.RandomState(1)\n",
        "X = 10 * rng.rand(100, 3)\n",
        "y = 0.5 + np.dot(X, [1.5, -2., 1.])\n",
        "\n",
        "model.fit(X, y)\n",
        "print(model.intercept_)\n",
        "print(model.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2 - Logistic Regression (Pure Python)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3 - Example Apps : Breast Cancer Clsssification using Logistic Regression (sklearn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0 : Import Modules, Functions and Constant\n",
        "Import modules for using on this file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pandas Module : For Dataframe Manager\n",
        "import pandas as pd\n",
        "\n",
        "# Numpy : Array operations.\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib : Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seaborn: statistical data visualization \n",
        "import seaborn as sns\n",
        "\n",
        "# Use `inline` mode for visualizing the figure directly on Colab.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import Test/Train dataset splitter module from scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import the model class from scikit-learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# scikit-learn.Metrics : Module for quantifying the quality of predictions\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 - Import Dataset\n",
        "\n",
        "First step We'll take a look into the data file. Here is the example dataset contain the data of a medical record from the diabatics patients. This dataset is from the kaggle (link...). You can try with you own data later on. But first/ let's take a look into our sample datafile first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load dataset from .CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Load dataset from .CSV file.\n",
        "\n",
        "# Pandas Module : For Dataframe Manager\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset CSV file. \n",
        "dataset = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "# Look inside the dataframe\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In Python Notebook (including the Google Colab), some `datatype` will be automatically formatted as you print it out. Try calling the variable name without using `print(...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tips - How to Access each data element\n",
        "You can access each element of data using header string. Noted that it's Case Sensitive, Upper and Lower case have to be perfactly matched."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " # Get Insulin data of ALL patients. Using object-like syntax.\n",
        " dataset.Insulin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " # Get Insulin data of ALL patients. Using dictionary-like syntax.\n",
        " dataset['Insulin']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " # By using a list, you can access multiple feature at a time.\n",
        " output_feature = ['Insulin', 'BMI']\n",
        " dataset[output_feature]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To get all feature from first patients (The first Row, Index[0]).\n",
        "dataset.loc[0] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To get all feature from Row Index[0] to Index[3].\n",
        "dataset.loc[0:3] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To get Row Index[0] to Index[3], On column 'Insulin' to 'Age'. (Including all columns in between)\n",
        "dataset.loc[0:3, 'Insulin':'Age'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To get Row Index[0] to Index[3], On specific column which are 'BMI'and 'Age'.\n",
        "dataset.loc[0:3, ['BMI', 'Age']] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tips - Load you own CSV dataset\n",
        "For these example, a comma-separated values (CSV) file format has been used. If you wish to use your own dataset then you can upload it and put the filename on the function. **Please make sure the you use the csv file with a header on first row. Otherwise, use `header=None`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset file. \n",
        "dataset = pd.read_csv(\"dataset_MyOwnData_SingleRowHeader.csv\")\n",
        "\n",
        "# Look inside the dataframe\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In case of the `CSV without Header`, you might add you own header manually. Otherwsie, Pandas will put the number for each row and column so you can use it to access specific data element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load NO HEADER dataset file. \n",
        "dataset = pd.read_csv(\"dataset_MyOwnData_NoHeader.csv\", header = None)\n",
        "\n",
        "# Look inside the dataframe\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load NO HEADER dataset file. But use our own custom feature's name\n",
        "custom_feature_name = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
        "dataset = pd.read_csv(\"dataset_MyOwnData_NoHeader.csv\", header = None, names=custom_feature_name)\n",
        "\n",
        "# Look inside the dataframe\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ATTENTION - Check the data BEFORE going onto next section.\n",
        "Please noted the all the code cells below are based on the default feature's label from the default dataset. So, if error occured, please make sure that the dataset and feature's label are matched. \n",
        "\n",
        "Please run one of these options below.\n",
        "\n",
        "1.   Use the default dataset.\n",
        "2.   Use my own dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Option 1 - Use the default dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reload the default dataset file and apply a custom feature name.\n",
        "\n",
        "# Load dataset CSV file.\n",
        "custom_feature_name = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
        "dataset = pd.read_csv(\"dataset.csv\", header = 0, names = custom_feature_name)\n",
        "\n",
        "# Look inside the dataframe\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Option 2 - Use my own dataset\n",
        "If you choos this option, Please make sure to change the selected_feature on the `Section 2 - Feature Selection` to match with your own dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Put your code here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 - Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Features Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a list of selected feature\n",
        "input_feature = ['insulin', 'bmi', 'age','glucose','bp']\n",
        "output_feature = 'label'\n",
        "\n",
        "# Create lists of input and output\n",
        "input_data = dataset[input_feature] \n",
        "output_data = dataset[output_feature]\n",
        "\n",
        "print(input_data)\n",
        "print(output_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test/Train Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Test/Train dataset splitter module from scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data. In this case, we use 70% for Training, and 30% for Testing.\n",
        "input_train, input_test, output_train, output_test = train_test_split(\n",
        "    input_data,\n",
        "    output_data, \n",
        "    test_size = 0.3 , \n",
        "    random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3 - Fit the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a model object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the model class from scikit-learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create `model object` by Instantiate a class\n",
        "model = LogisticRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit the model using Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(input_train, output_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4 - Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get a predicted data from the Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_predicted = model.predict(input_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# scikit-learn.Metrics : Module for quantifying the quality of predictions\n",
        "from sklearn import metrics\n",
        "\n",
        "# Get the confusion matrix\n",
        "confusion_matrix = metrics.confusion_matrix(output_test, output_predicted)\n",
        "\n",
        "# Print the confusion_matrix\n",
        "confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output show the number of Target vs Predicted of each class. \n",
        "\n",
        "*   confusion_matrix [0] [0] : Target is 0, Predicted as 0  = True Negative, TN\n",
        "*   confusion_matrix [0] [1] : Target is 0, Predicted as 1  = False Positive, FP\n",
        "*   confusion_matrix [1] [0] : Target is 1, Predicted as 0  = False Negative, FN\n",
        "*   confusion_matrix [1] [1] : Target is 1, Predicted as 1  = True Positive, TP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (Optional) Display the Confusion Matrix using Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Numpy : Array operations.\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib : Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seaborn: statistical data visualization \n",
        "import seaborn as sns\n",
        "\n",
        "# Use `inline` mode for visualizing the figure directly on Colab.\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classname of Label for visialization.\n",
        "output_classname = ['0','1']   \n",
        "\n",
        "# Creat plot object (figure and axis)\n",
        "figure_handler, axis_handler = plt.subplots()\n",
        "\n",
        "# Plot Data as a Heetmap using Seaborn.heatmap()\n",
        "axis_tickmark = np.arange(len(output_classname))    \n",
        "plt.xticks(axis_tickmark, output_classname)\n",
        "plt.yticks(axis_tickmark, output_classname)\n",
        "sns.heatmap(confusion_matrix, cmap=\"crest_r\", annot=True, fmt='g')\n",
        "\n",
        "# Add Title and Label into figure\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "axis_handler.xaxis.set_label_position(\"top\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display Accuracy, Precision, Recall, and F1-Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Option 1 - Use sklearn module's functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get value using sciket-learn.metrics\n",
        "accuracy = metrics.accuracy_score(output_test, output_predicted)\n",
        "precision = metrics.precision_score(output_test, output_predicted)\n",
        "recall = metrics.recall_score(output_test, output_predicted)\n",
        "f1_score = metrics.f1_score(output_test, output_predicted)\n",
        "\n",
        "# Print the result\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Option 2 - Do it from scrach.\n",
        "\n",
        "Accuracy = TP+TN/TP+FP+FN+TN  \n",
        "Precision = TP/TP+FP  \n",
        "Recall = TP/TP+FN  \n",
        "F1 Score = 2*(Recall * Precision) / (Recall + Precision)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get TP, TN, FP, FN from confusion_matrix\n",
        "TP = confusion_matrix[1][1]\n",
        "TN = confusion_matrix[0][0]\n",
        "FP = confusion_matrix[0][1]\n",
        "FN = confusion_matrix[1][0]\n",
        "\n",
        "# Calculating using the equation.\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "f1_score =  2 * ((precision * recall ) / (precision + recall))\n",
        "\n",
        "# Print the result\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wFdFZ3Y-svTr",
        "cqbna6vN50Of"
      ],
      "name": "Funda - 1A- Metrics",
      "provenance": []
    },
    "interpreter": {
      "hash": "85ece3460b2fd6dc7509572ece23929b4d3a20b0182db721d73605c8e6de4194"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
