{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bronze-upset",
   "metadata": {},
   "source": [
    "## **Gradient descent**\n",
    "\n",
    "Suppose we have a funtion\n",
    "\n",
    "$f(x) = x^2 - 4 x + 5$\n",
    "\n",
    "Find $x$ that minimize a given function\n",
    "\n",
    "$f'(x) = 2 x - 4 = 0$\n",
    "\n",
    "therefore $x = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient by hand\n",
    "alpha = 0.02\n",
    "x = 10.0\n",
    "\n",
    "def f(x):\n",
    "    return x ** 2 - (4 * x) + 5\n",
    "\n",
    "def compute_grad(x):\n",
    "    grad = 2 * x - 4\n",
    "    return grad\n",
    "\n",
    "for _ in range(1000):\n",
    "    x = x - alpha * compute_grad(x)\n",
    "print(\"x_min = \", x)\n",
    "print(\"f(x) = \", f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-perth",
   "metadata": {},
   "source": [
    "## **Gradient descent with Pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(10, dtype=torch.float, requires_grad=True)\n",
    "cost = torch.sum(x * x - 4 * x + 5)\n",
    "cost.backward() # calculate gradient using \"backward\"\n",
    "print(x.grad) # gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descpent with torch\n",
    "x = torch.tensor(10, dtype=torch.float, requires_grad=True)  # initialize x\n",
    "\n",
    "def loss(x):\n",
    "    return torch.sum(x * x - 4 * x + 5)  # define cost function\n",
    "\n",
    "for _ in range(1000):\n",
    "    cost = loss(x)\n",
    "    cost.backward(retain_graph=True)\n",
    "    x.data.sub_(alpha * x.grad)\n",
    "    x.grad.data.zero_()\n",
    "print(x.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-colors",
   "metadata": {},
   "source": [
    "## **Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-dialogue",
   "metadata": {},
   "source": [
    "Try finding gradient (slope) of the following equation at $x = \\pi$\n",
    "\n",
    "$f(x) = 3 cos(x) + 4 sin(x) + 4 x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-values",
   "metadata": {},
   "source": [
    "## **Gradient descent for regression**\n",
    "\n",
    "Here, we will use gradient descent to solve linear regression. There are multiple implementation the gradient descent to solve regression\n",
    "1. compute gradient\n",
    "2. using Pytorch to calculate gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mattnedrich/GradientDescentExample/master/data.csv\",\n",
    "    header=None, names=['x', 'y']\n",
    ").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad(X, y, theta):\n",
    "    m = len(X)\n",
    "    theta_grad = np.array([0, 0])\n",
    "    for i in range(m):\n",
    "        theta_grad[0] += (1./(m))*((theta[0] + theta[1]*X[i]) - y[i])\n",
    "        theta_grad[1] += (1./(m))*((theta[0] + theta[1]*X[i]) - y[i])*X[i]\n",
    "    return theta_grad\n",
    "\n",
    "def compute_cost(X, y, theta):\n",
    "    m = len(X)\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        J += (1./(2*m))*((theta[0] + theta[1]*X[i]) - y[i])**2\n",
    "    return J\n",
    "\n",
    "X = data[:,0]\n",
    "y = data[:,1]\n",
    "J = [] # history of cost\n",
    "theta = np.array([0, -1]) # intial theta\n",
    "n_iter = 3000\n",
    "for i in tqdm(range(n_iter)):\n",
    "    theta_grad = compute_grad(X, y, theta)\n",
    "    theta = theta - 0.0001 * theta_grad\n",
    "    J.append(compute_cost(X, y, theta))\n",
    "print(f'final theta = {theta}')\n",
    "print(f'final cost = {J[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 100, 0.2)\n",
    "y_fit = theta[0] + (theta[1] * x)\n",
    "\n",
    "plt.plot(x, y_fit)\n",
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-section",
   "metadata": {},
   "source": [
    "## Gradient descent for regression using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mattnedrich/GradientDescentExample/master/data.csv\",\n",
    "    header=None, names=['x', 'y']\n",
    ").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "plt.xlabel(\"$X$\")\n",
    "plt.ylabel(\"$Y$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X, y as torch tensor\n",
    "X = data[:, 0]\n",
    "X = torch.tensor(np.vstack((np.ones(len(X)), X)).T).float()\n",
    "y = torch.tensor(y).float()\n",
    "\n",
    "# initialized theta\n",
    "theta = torch.tensor([[0., -1.]], requires_grad=True).t()\n",
    "theta.retain_grad()  # specific to Pytorch, non-leaf tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(y, theta):\n",
    "    y_pred = torch.matmul(X, theta).view(-1)\n",
    "    return ((y - y_pred) ** 2 / len(y)).sum() / (2 * len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "for _ in range(2000):\n",
    "    loss = cal_loss(y, theta)\n",
    "    loss.backward(retain_graph=True)\n",
    "    theta.data.sub_(alpha * theta.grad)\n",
    "    theta.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_ = theta.data.numpy().ravel()\n",
    "print(\"Final parameters: \", theta_)\n",
    "print(\"Cost: \", cal_loss(y, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 100, 0.2)\n",
    "y_fit = theta_[0] + theta_[1] * x\n",
    "\n",
    "plt.plot(x, y_fit)\n",
    "plt.scatter(data[:, 0], data[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-mileage",
   "metadata": {},
   "source": [
    "## **Gradient Descent for logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example intuition of logistic loss calculation\n",
    "target = torch.tensor([1, 0, 1])\n",
    "pred   = torch.tensor([0.9, 0.4, 0.2])\n",
    "def calculate_loss(y, y_pred):\n",
    "    loss = torch.where(y == 1, 1 - y_pred, y_pred).mean()\n",
    "    return loss\n",
    "calculate_loss(target, pred) # loss (0.1 + 0.4 + 0.8) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"https://raw.githubusercontent.com/Benlau93/Machine-Learning-by-Andrew-Ng-in-Python/master/LogisticRegression/ex2data1.txt\"\n",
    "df = pd.read_csv(path, names=[\"x1\", \"x2\", \"y\"], skiprows=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"x1\", y=\"x2\",\n",
    "        c=df.y.map({1:'blue', 0:'red'}))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(df[['x1', 'x2']].values)\n",
    "X = torch.cat((torch.ones(len(X), 1), X), dim=-1)\n",
    "y = torch.tensor(df['y'].values.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try writing your own sigmoid function\n",
    "def calculate_loss(y, y_pred):\n",
    "    loss = ((y * (1 - y_pred)) + (1 - y) * (y_pred)).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.tensor([[0.5, 0.5, 0.5]], requires_grad=True).double()\n",
    "theta.retain_grad()\n",
    "y_pred = torch.sigmoid(torch.matmul(X, theta.t()).view(-1))\n",
    "print(\"Accuracy (initialized theta): \", accuracy_score(y, y_pred.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.tensor([[0.5, 0.5, 0.5]], requires_grad=True).double()\n",
    "theta.retain_grad()  # specific to Pytorch, non-leaf tensor\n",
    "\n",
    "alpha = 0.01\n",
    "for _ in tqdm(range(1000)):\n",
    "    y_pred = torch.sigmoid(torch.matmul(X, theta.t()).view(-1))\n",
    "    loss = calculate_loss(y, y_pred)\n",
    "    loss.backward(retain_graph=True)  # calculate gradient\n",
    "    theta.data.sub_(alpha * theta.grad)\n",
    "    theta.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure accuracy after training\n",
    "y_pred = torch.sigmoid(torch.matmul(X, theta.t()).view(-1))\n",
    "accuracy_score(y, (y_pred > 0.5).numpy().astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-composite",
   "metadata": {},
   "source": [
    "## **Using sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "logist = LogisticRegression().fit(df[['x1', 'x2']].values, y.numpy())\n",
    "y_pred = logist.predict(df[['x1', 'x2']].values)\n",
    "accuracy_score(y, (y_pred > 0.5).astype(int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
